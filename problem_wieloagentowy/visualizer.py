"""
Modu≈Ç do wizualizacji wynik√≥w eksperyment√≥w wieloagentowych
w ≈õrodowisku Texas Hold'em
"""

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from pathlib import Path
from typing import Dict, Any, List, Tuple
import pandas as pd
from matplotlib.patches import Rectangle
import warnings
warnings.filterwarnings('ignore')

# Konfiguracja matplotlib
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class ResultsVisualizer:
    """Klasa do tworzenia wizualizacji wynik√≥w eksperyment√≥w"""
    
    def __init__(self, results: Dict[str, Dict[str, Any]]):
        """
        Inicjalizuje wizualizator
        
        Args:
            results: S≈Çownik z wynikami eksperyment√≥w
        """
        self.results = results
        self.output_dir = Path("plots")
        self.output_dir.mkdir(exist_ok=True)
        
        # Konfiguracja kolor√≥w
        self.colors = {
            'PPO_Conservative': '#1f77b4',
            'PPO_Aggressive': '#ff7f0e', 
            'A2C_Standard': '#2ca02c',
            'DQN_Standard': '#d62728'
        }
        
        print(f"üìä Wizualizator zainicjalizowany dla {len(results)} algorytm√≥w")
    
    def create_all_plots(self):
        """Tworzy wszystkie wykresy"""
        print("üé® Tworzenie wizualizacji...")
        
        if not self.results:
            print("‚ùå Brak danych do wizualizacji")
            return
        
        # Podstawowe wykresy
        self.plot_algorithm_comparison()
        self.plot_performance_metrics()
        self.plot_hyperparameter_analysis()
        self.plot_training_efficiency()
        
        # Szczeg√≥≈Çowe analizy
        self.plot_reward_distribution()
        self.plot_stability_analysis()
        self.create_summary_dashboard()
        
        print(f"‚úÖ Wszystkie wykresy zapisane w folderze: {self.output_dir}")
    
    def plot_algorithm_comparison(self):
        """Wykres por√≥wnania algorytm√≥w"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Przygotowanie danych
        algorithms = list(self.results.keys())
        mean_rewards = [self.results[alg]['mean_reward'] for alg in algorithms]
        std_rewards = [self.results[alg]['std_reward'] for alg in algorithms]
        colors = [self.colors.get(alg, '#333333') for alg in algorithms]
        
        # Wykres 1: ≈örednie nagrody z b≈Çƒôdami
        bars1 = ax1.bar(algorithms, mean_rewards, yerr=std_rewards, 
                       capsize=5, color=colors, alpha=0.7, edgecolor='black')
        ax1.set_title('Por√≥wnanie ≈õrednich nagr√≥d algorytm√≥w', fontsize=14, fontweight='bold')
        ax1.set_ylabel('≈örednia nagroda')
        ax1.tick_params(axis='x', rotation=45)
        ax1.grid(axis='y', alpha=0.3)
        
        # Dodanie warto≈õci na wykresie
        for bar, mean_val, std_val in zip(bars1, mean_rewards, std_rewards):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + std_val,
                    f'{mean_val:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # Wykres 2: Czas treningu
        training_times = [self.results[alg]['training_time']/60 for alg in algorithms]
        bars2 = ax2.bar(algorithms, training_times, color=colors, alpha=0.7, edgecolor='black')
        ax2.set_title('Czas treningu algorytm√≥w', fontsize=14, fontweight='bold')
        ax2.set_ylabel('Czas treningu [minuty]')
        ax2.tick_params(axis='x', rotation=45)
        ax2.grid(axis='y', alpha=0.3)
        
        # Dodanie warto≈õci na wykresie
        for bar, time_val in zip(bars2, training_times):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{time_val:.1f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'algorithm_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‚úÖ Wykres por√≥wnania algorytm√≥w utworzony")
    
    def plot_performance_metrics(self):
        """Wykres metryk wydajno≈õci"""
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # Przygotowanie danych
        algorithms = list(self.results.keys())
        mean_rewards = [self.results[alg]['mean_reward'] for alg in algorithms]
        training_times = [self.results[alg]['training_time']/60 for alg in algorithms]
        std_rewards = [self.results[alg]['std_reward'] for alg in algorithms]
        
        # Wykres scatter z rozmiarem punkt√≥w proporcjonalnym do stabilno≈õci
        scatter = ax.scatter(training_times, mean_rewards, 
                           s=[300/(std if std > 1e-5 else 1e-5) for std in std_rewards],
                           c=[self.colors.get(alg, '#333333') for alg in algorithms],
                           alpha=0.7, edgecolors='black', linewidths=2)
        
        # Etykiety punkt√≥w
        for i, alg in enumerate(algorithms):
            ax.annotate(alg, (training_times[i], mean_rewards[i]),
                       xytext=(5, 5), textcoords='offset points',
                       fontsize=10, fontweight='bold')
        
        ax.set_xlabel('Czas treningu [minuty]', fontsize=12)
        ax.set_ylabel('≈örednia nagroda', fontsize=12)
        ax.set_title('Wydajno≈õƒá vs Czas treningu\n(Rozmiar punktu = stabilno≈õƒá)', 
                    fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # Dodanie linii trendu
        z = np.polyfit(training_times, mean_rewards, 1)
        p = np.poly1d(z)
        ax.plot(training_times, p(training_times), "r--", alpha=0.8, linewidth=2)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'performance_metrics.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‚úÖ Wykres metryk wydajno≈õci utworzony")
    
    def plot_hyperparameter_analysis(self):
        """Analiza wp≈Çywu hiperparametr√≥w"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()
        
        # Parametry do analizy
        params_to_analyze = ['learning_rate', 'gamma', 'batch_size', 'ent_coef']
        
        for i, param in enumerate(params_to_analyze):
            ax = axes[i]
            
            # Zbieranie danych
            param_values = []
            rewards = []
            algorithm_names = []
            
            for alg_name, results in self.results.items():
                if param in results['hyperparams']:
                    param_values.append(results['hyperparams'][param])
                    rewards.append(results['mean_reward'])
                    algorithm_names.append(alg_name)
            
            if param_values:
                # Wykres scatter
                colors = [self.colors.get(alg, '#333333') for alg in algorithm_names]
                scatter = ax.scatter(param_values, rewards, c=colors, s=100, 
                                   alpha=0.7, edgecolors='black')
                
                # Etykiety
                for j, alg in enumerate(algorithm_names):
                    ax.annotate(alg, (param_values[j], rewards[j]),
                               xytext=(5, 5), textcoords='offset points',
                               fontsize=8)
                
                ax.set_xlabel(param.replace('_', ' ').title())
                ax.set_ylabel('≈örednia nagroda')
                ax.set_title(f'Wp≈Çyw {param} na wydajno≈õƒá')
                ax.grid(True, alpha=0.3)
                
                # Linia trendu je≈õli mo≈ºliwa
                if len(param_values) > 1:
                    try:
                        z = np.polyfit(param_values, rewards, 1)
                        p = np.poly1d(z)
                        x_trend = np.linspace(min(param_values), max(param_values), 100)
                        ax.plot(x_trend, p(x_trend), "r--", alpha=0.5)
                    except:
                        pass
            else:
                ax.text(0.5, 0.5, f'Brak danych\ndla {param}', 
                       ha='center', va='center', transform=ax.transAxes)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'hyperparameter_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‚úÖ Analiza hiperparametr√≥w utworzona")
    
    def plot_training_efficiency(self):
        """Wykres efektywno≈õci treningu"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # Przygotowanie danych
        algorithms = list(self.results.keys())
        efficiencies = []
        
        for alg in algorithms:
            reward = self.results[alg]['mean_reward']
            time = self.results[alg]['training_time'] / 60  # w minutach
            efficiency = reward / time if time > 0 else 0
            efficiencies.append(efficiency)
        
        # Wykres s≈Çupkowy z gradientem
        bars = ax.bar(algorithms, efficiencies, 
                     color=[self.colors.get(alg, '#333333') for alg in algorithms],
                     alpha=0.7, edgecolor='black', linewidth=2)
        
        # Dodanie warto≈õci na s≈Çupkach
        for bar, eff in zip(bars, efficiencies):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{eff:.4f}', ha='center', va='bottom', fontweight='bold')
        
        ax.set_title('Efektywno≈õƒá treningu algorytm√≥w\n(Nagroda / Czas treningu)', 
                    fontsize=14, fontweight='bold')
        ax.set_ylabel('Efektywno≈õƒá [nagroda/minuta]')
        ax.tick_params(axis='x', rotation=45)
        ax.grid(axis='y', alpha=0.3)
        
        # Dodanie ≈õredniej linii
        mean_efficiency = np.mean(efficiencies)
        ax.axhline(y=mean_efficiency, color='red', linestyle='--', 
                  label=f'≈örednia: {mean_efficiency:.4f}')
        ax.legend()
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'training_efficiency.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‚úÖ Wykres efektywno≈õci treningu utworzony")
    
    def plot_reward_distribution(self):
        """Rozk≈Çad nagr√≥d dla ka≈ºdego algorytmu"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        algorithms = list(self.results.keys())
        
        for i, alg in enumerate(algorithms):
            if i >= len(axes):
                break
                
            ax = axes[i]
            
            # Symulacja rozk≈Çadu nagr√≥d na podstawie ≈õredniej i odchylenia
            mean_reward = self.results[alg]['mean_reward']
            std_reward = self.results[alg]['std_reward']
            
            # Generuj pr√≥bki rozk≈Çadu normalnego
            samples = np.random.normal(mean_reward, std_reward, 1000)
            
            # Histogram
            ax.hist(samples, bins=30, alpha=0.7, color=self.colors.get(alg, '#333333'),
                   edgecolor='black', density=True)
            
            # Krzywa rozk≈Çadu normalnego
            x = np.linspace(samples.min(), samples.max(), 100)
            y = (1 / (std_reward * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean_reward) / std_reward) ** 2)
            ax.plot(x, y, 'r-', linewidth=2, label='Rozk≈Çad normalny')
            
            ax.set_title(f'{alg}\nŒº={mean_reward:.3f}, œÉ={std_reward:.3f}')
            ax.set_xlabel('Nagroda')
            ax.set_ylabel('Gƒôsto≈õƒá')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # Ukryj puste subplot'y
        for i in range(len(algorithms), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'reward_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‚úÖ Rozk≈Çad nagr√≥d utworzony")
    
    def plot_stability_analysis(self):
        """Analiza stabilno≈õci algorytm√≥w"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        algorithms = list(self.results.keys())
        mean_rewards = [self.results[alg]['mean_reward'] for alg in algorithms]
        std_rewards = [self.results[alg]['std_reward'] for alg in algorithms]
        colors = [self.colors.get(alg, '#333333') for alg in algorithms]
        
        # Wykres 1: Wsp√≥≈Çczynnik zmienno≈õci
        cv_values = [std/abs(mean) if mean != 0 else 0 for mean, std in zip(mean_rewards, std_rewards)]
        
        bars1 = ax1.bar(algorithms, cv_values, color=colors, alpha=0.7, edgecolor='black')
        ax1.set_title('Stabilno≈õƒá algorytm√≥w\n(Wsp√≥≈Çczynnik zmienno≈õci)', fontweight='bold')
        ax1.set_ylabel('Wsp√≥≈Çczynnik zmienno≈õci (œÉ/Œº)')
        ax1.tick_params(axis='x', rotation=45)
        ax1.grid(axis='y', alpha=0.3)
        
        # Dodanie warto≈õci
        for bar, cv in zip(bars1, cv_values):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{cv:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # Wykres 2: Stosunek nagrody do wariancji
        reward_to_var = [mean/std if std > 0 else 0 for mean, std in zip(mean_rewards, std_rewards)]
        
        bars2 = ax2.bar(algorithms, reward_to_var, color=colors, alpha=0.7, edgecolor='black')
        ax2.set_title('Stosunek nagrody do wariancji\n(Wy≈ºsze = lepsze)', fontweight='bold')
        ax2.set_ylabel('Nagroda / Odchylenie')
        ax2.tick_params(axis='x', rotation=45)
        ax2.grid(axis='y', alpha=0.3)
        
        # Dodanie warto≈õci
        for bar, ratio in zip(bars2, reward_to_var):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{ratio:.2f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'stability_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‚úÖ Analiza stabilno≈õci utworzona")
    
    def create_summary_dashboard(self):
        """Tworzy dashboard z podsumowaniem"""
        fig = plt.figure(figsize=(20, 12))
        
        # Definicja siatki
        gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)
        
        # 1. Por√≥wnanie nagr√≥d
        ax1 = fig.add_subplot(gs[0, :2])
        algorithms = list(self.results.keys())
        mean_rewards = [self.results[alg]['mean_reward'] for alg in algorithms]
        std_rewards = [self.results[alg]['std_reward'] for alg in algorithms]
        colors = [self.colors.get(alg, '#333333') for alg in algorithms]
        
        bars = ax1.bar(algorithms, mean_rewards, yerr=std_rewards, 
                      capsize=5, color=colors, alpha=0.7)
        ax1.set_title('≈örednie nagrody algorytm√≥w', fontweight='bold')
        ax1.set_ylabel('Nagroda')
        ax1.tick_params(axis='x', rotation=45)
        
        # 2. Czas treningu
        ax2 = fig.add_subplot(gs[0, 2:])
        training_times = [self.results[alg]['training_time']/60 for alg in algorithms]
        ax2.pie(training_times, labels=algorithms, autopct='%1.1f%%', 
               colors=colors, startangle=90)
        ax2.set_title('Proporcje czasu treningu', fontweight='bold')
        
        # 3. Scatter plot wydajno≈õci
        ax3 = fig.add_subplot(gs[1, :2])
        ax3.scatter(training_times, mean_rewards, 
                   s=[300/(std if std > 1e-5 else 1e-5) for std in std_rewards],
                   c=colors, alpha=0.7, edgecolors='black')
        ax3.set_xlabel('Czas treningu [min]')
        ax3.set_ylabel('≈örednia nagroda')
        ax3.set_title('Wydajno≈õƒá vs Czas', fontweight='bold')
        
        # 4. Tabela wynik√≥w
        ax4 = fig.add_subplot(gs[1, 2:])
        ax4.axis('off')
        
        # Przygotowanie danych do tabeli
        table_data = []
        for alg in algorithms:
            data = self.results[alg]
            table_data.append([
                alg,
                f"{data['mean_reward']:.3f}",
                f"{data['std_reward']:.3f}",
                f"{data['training_time']/60:.1f}m"
            ])
        
        table = ax4.table(cellText=table_data,
                         colLabels=['Algorytm', '≈örednia', 'Odch. std', 'Czas'],
                         cellLoc='center',
                         loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1.2, 1.5)
        ax4.set_title('Tabela wynik√≥w', fontweight='bold', pad=20)
        
        # 5. Ranking algorytm√≥w
        ax5 = fig.add_subplot(gs[2, :])
        
        # Sortowanie wed≈Çug nagrody
        sorted_algs = sorted(zip(algorithms, mean_rewards, std_rewards, training_times),
                           key=lambda x: x[1], reverse=True)
        
        y_pos = np.arange(len(sorted_algs))
        rewards = [x[1] for x in sorted_algs]
        alg_names = [x[0] for x in sorted_algs]
        
        bars = ax5.barh(y_pos, rewards, color=[self.colors.get(alg, '#333333') for alg in alg_names])
        ax5.set_yticks(y_pos)
        ax5.set_yticklabels(alg_names)
        ax5.set_xlabel('≈örednia nagroda')
        ax5.set_title('Ranking algorytm√≥w', fontweight='bold')
        
        # Dodanie medali
        medals = ['ü•á', 'ü•à', 'ü•â', '4Ô∏è‚É£']
        for i, (bar, medal) in enumerate(zip(bars, medals)):
            if i < len(medals):
                ax5.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                        medal, ha='left', va='center', fontsize=16)
        
        # G≈Ç√≥wny tytu≈Ç
        fig.suptitle('Dashboard wynik√≥w eksperymentu Texas Hold\'em', 
                    fontsize=20, fontweight='bold', y=0.98)
        
        plt.savefig(self.output_dir / 'summary_dashboard.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‚úÖ Dashboard podsumowujƒÖcy utworzony")
    
    def generate_report_data(self) -> Dict[str, Any]:
        """Generuje dane do raportu"""
        if not self.results:
            return {}
        
        # Najlepszy algorytm
        best_alg = max(self.results.items(), key=lambda x: x[1]['mean_reward'])
        worst_alg = min(self.results.items(), key=lambda x: x[1]['mean_reward'])
        
        # Najszybszy trening
        fastest_alg = min(self.results.items(), key=lambda x: x[1]['training_time'])
        
        # Najstabilniejszy (najmniejsze std)
        most_stable = min(self.results.items(), key=lambda x: x[1]['std_reward'])
        
        # Statystyki og√≥lne
        all_rewards = [data['mean_reward'] for data in self.results.values()]
        all_times = [data['training_time'] for data in self.results.values()]
        
        report_data = {
            'experiment_summary': {
                'total_algorithms': len(self.results),
                'best_algorithm': best_alg[0],
                'best_score': best_alg[1]['mean_reward'],
                'worst_algorithm': worst_alg[0],
                'worst_score': worst_alg[1]['mean_reward'],
                'score_range': best_alg[1]['mean_reward'] - worst_alg[1]['mean_reward'],
                'fastest_algorithm': fastest_alg[0],
                'fastest_time': fastest_alg[1]['training_time'],
                'most_stable_algorithm': most_stable[0],
                'lowest_std': most_stable[1]['std_reward'],
                'average_score': np.mean(all_rewards),
                'average_time': np.mean(all_times),
                'total_training_time': sum(all_times)
            },
            'detailed_results': self.results
        }
        
        return report_data
    
    def save_report_data(self, filepath: str = None):
        """Zapisuje dane raportu do pliku"""
        if filepath is None:
            filepath = 'C:/Users/zuzan/PycharmProjects/problem_wieloagentowy/report_data.txt'
        
        report_data = self.generate_report_data()
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("RAPORT Z EKSPERYMENTU TEXAS HOLD'EM\n")
            f.write("=" * 50 + "\n\n")
            
            summary = report_data['experiment_summary']
            f.write("PODSUMOWANIE EKSPERYMENTU:\n")
            f.write("-" * 30 + "\n")
            f.write(f"Liczba algorytm√≥w: {summary['total_algorithms']}\n")
            f.write(f"Najlepszy algorytm: {summary['best_algorithm']} ({summary['best_score']:.3f})\n")
            f.write(f"Najgorszy algorytm: {summary['worst_algorithm']} ({summary['worst_score']:.3f})\n")
            f.write(f"Rozstƒôp wynik√≥w: {summary['score_range']:.3f}\n")
            f.write(f"Najszybszy trening: {summary['fastest_algorithm']} ({summary['fastest_time']:.1f}s)\n")
            f.write(f"Najstabilniejszy: {summary['most_stable_algorithm']} (œÉ={summary['lowest_std']:.3f})\n")
            f.write(f"≈öredni wynik: {summary['average_score']:.3f}\n")
            f.write(f"≈öredni czas treningu: {summary['average_time']:.1f}s\n")
            f.write(f"Ca≈Çkowity czas: {summary['total_training_time']:.1f}s\n\n")
            
            f.write("SZCZEG√ì≈ÅOWE WYNIKI:\n")
            f.write("-" * 30 + "\n")
            for alg_name, data in self.results.items():
                f.write(f"\n{alg_name}:\n")
                f.write(f"  ≈örednia nagroda: {data['mean_reward']:.3f} ¬± {data['std_reward']:.3f}\n")
                f.write(f"  Czas treningu: {data['training_time']:.1f}s\n")
                f.write(f"  Efektywno≈õƒá: {data['mean_reward']/(data['training_time']/60):.4f} nagroda/min\n")
                f.write(f"  Timesteps: {data['total_timesteps']}\n")
        
        print(f"üìù Dane raportu zapisane do: {filepath}")

# Test modu≈Çu
if __name__ == "__main__":
    print("üß™ Test modu≈Çu wizualizacji...")
    
    # Przyk≈Çadowe dane testowe
    test_results = {
        'PPO_Conservative': {
            'mean_reward': 0.15,
            'std_reward': 0.05,
            'training_time': 300,
            'hyperparams': {'learning_rate': 3e-4, 'gamma': 0.99, 'batch_size': 64},
            'total_timesteps': 100000
        },
        'PPO_Aggressive': {
            'mean_reward': 0.12,
            'std_reward': 0.08,
            'training_time': 250,
            'hyperparams': {'learning_rate': 1e-3, 'gamma': 0.95, 'batch_size': 128},
            'total_timesteps': 100000
        },
        'A2C_Standard': {
            'mean_reward': 0.08,
            'std_reward': 0.04,
            'training_time': 200,
            'hyperparams': {'learning_rate': 7e-4, 'gamma': 0.99, 'batch_size': 32},
            'total_timesteps': 100000
        }
    }
    
    # Test wizualizatora
    visualizer = ResultsVisualizer(test_results)
    
    try:
        visualizer.create_all_plots()
        visualizer.save_report_data()
        print("‚úÖ Test wizualizacji zako≈Ñczony pomy≈õlnie")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd podczas testu: {e}")