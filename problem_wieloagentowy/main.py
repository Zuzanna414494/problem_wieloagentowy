"""
Projekt 6: Problem wieloagentowy - Texas Hold'em
GÅ‚Ã³wny plik do uruchomienia eksperymentÃ³w
"""

import os
import sys
import time
from pathlib import Path

# Tworzenie struktury folderÃ³w
def setup_directories():
    """Tworzy niezbÄ™dne foldery"""
    directories = ['models', 'logs', 'results', 'plots']
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
    print("âœ… Struktura folderÃ³w utworzona")

def check_dependencies():
    """Sprawdza czy wszystkie biblioteki sÄ… zainstalowane"""
    required_packages = [
        'pettingzoo', 'stable_baselines3', 'matplotlib', 
        'numpy', 'torch', 'gymnasium'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ BrakujÄ…ce pakiety:")
        for package in missing_packages:
            print(f"   - {package}")
        print("\nğŸ“¦ Zainstaluj brakujÄ…ce pakiety:")
        print("pip install stable-baselines3[extra] pettingzoo[classic] matplotlib torch")
        return False
    
    print("âœ… Wszystkie zaleÅ¼noÅ›ci sÄ… zainstalowane")
    return True

def main():
    """GÅ‚Ã³wna funkcja projektu"""
    print("=" * 60)
    print("ğŸ¯ PROJEKT WIELOAGENTOWY - TEXAS HOLD'EM")
    print("=" * 60)
    
    # Sprawdzenie zaleÅ¼noÅ›ci
    if not check_dependencies():
        return
    
    # Tworzenie struktury folderÃ³w
    setup_directories()
    
    # Import moduÅ‚Ã³w projektu
    try:
        from environment_wrapper import TexasHoldemWrapper
        from algorithms_config import AlgorithmsConfig
        from trainer import MultiAgentTrainer
        from visualizer import ResultsVisualizer
        
        print("âœ… Wszystkie moduÅ‚y zaÅ‚adowane pomyÅ›lnie")
    except ImportError as e:
        print(f"âŒ BÅ‚Ä…d importu: {e}")
        return
    
    # Konfiguracja eksperymentu
    print("\nğŸ”§ Konfiguracja eksperymentu:")
    config = {
        'n_players': 4,           # 4 graczy w Texas Hold'em
        'total_timesteps': 5000, # Liczba krokÃ³w treningu
        'eval_freq': 1000,        # CzÄ™stotliwoÅ›Ä‡ ewaluacji
        'n_eval_episodes': 5     # Liczba epizodÃ³w do ewaluacji
    }
    
    for key, value in config.items():
        print(f"   {key}: {value}")
    
    # Inicjalizacja trenera
    print("\nğŸ¤– Inicjalizacja trenera...")
    trainer = MultiAgentTrainer(
        n_players=config['n_players'],
        eval_freq=config['eval_freq'],
        n_eval_episodes=config['n_eval_episodes']
    )
    
    # Pobieranie konfiguracji algorytmÃ³w
    algorithms_config = AlgorithmsConfig.get_algorithms()
    print(f"ğŸ“‹ Skonfigurowane algorytmy: {list(algorithms_config.keys())}")
    
    # Trening wszystkich algorytmÃ³w
    print("\nğŸš€ RozpoczÄ™cie treningu algorytmÃ³w...")
    start_time = time.time()
    
    for i, (alg_name, config_data) in enumerate(algorithms_config.items(), 1):
        print(f"\n[{i}/{len(algorithms_config)}] Trenowanie: {alg_name}")
        print("-" * 40)
        
        try:
            trainer.train_algorithm(
                algorithm_name=alg_name,
                algorithm_class=config_data["class"],
                hyperparams=config_data["params"],
                total_timesteps=config['total_timesteps']
            )
            print(f"âœ… {alg_name} wytrenowany pomyÅ›lnie")
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d podczas treningu {alg_name}: {e}")
            continue
    
    total_time = time.time() - start_time
    print(f"\nâ±ï¸  CaÅ‚kowity czas treningu: {total_time/60:.1f} minut")
    
    # Analiza wynikÃ³w
    print("\nğŸ“Š Analiza wynikÃ³w...")
    trainer.compare_algorithms()
    
    # Tworzenie wizualizacji
    print("\nğŸ“ˆ Tworzenie wykresÃ³w...")
    visualizer = ResultsVisualizer(trainer.results)
    visualizer.create_all_plots()
    
    # Zapisanie wynikÃ³w
    print("\nğŸ’¾ Zapisywanie wynikÃ³w...")
    trainer.save_results('results/experiment_results.pkl')
    
    # Podsumowanie
    print("\n" + "=" * 60)
    print("ğŸ‰ EKSPERYMENT ZAKOÅƒCZONY POMYÅšLNIE!")
    print("=" * 60)
    print("ğŸ“ Wygenerowane pliki:")
    print("   ğŸ“Š plots/ - Wykresy i wizualizacje")
    print("   ğŸ¤– models/ - Wytrenowane modele")
    print("   ğŸ“ logs/ - Logi treningu")
    print("   ğŸ’¾ results/ - Dane eksperymentu")
    
    # WyÅ›wietlenie najlepszego algorytmu
    if trainer.results:
        best_alg = max(trainer.results.items(), 
                      key=lambda x: x[1]['mean_reward'])
        print(f"\nğŸ† Najlepszy algorytm: {best_alg[0]}")
        print(f"   Åšrednia nagroda: {best_alg[1]['mean_reward']:.2f}")

if __name__ == "__main__":
    main()